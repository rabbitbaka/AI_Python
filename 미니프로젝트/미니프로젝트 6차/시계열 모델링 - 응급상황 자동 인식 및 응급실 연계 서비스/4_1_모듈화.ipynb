{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **응급상황 자동 인식 및 응급실 연계 서비스**\n",
        "# **단계4 : 통합-모듈화**"
      ],
      "metadata": {
        "id": "4p06IPOk5xil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **0.미션**\n",
        "\n",
        "단계 4에서는, 단계1,2,3 에서 생성한 함수들을 모듈화하고, 단위 테스트 및 파이프라인 코드를 작성합니다."
      ],
      "metadata": {
        "id": "HRuiqkZnuq94"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **미션6**\n",
        "    * Python 코드 모듈화\n",
        "        * 각 모듈 코드 및 모델, 데이터파일을 일관성 있게 정리\n",
        "        * .py 파일 생성 ==> 라이브러리 로딩, 각 task를 위한 함수 생성\n"
      ],
      "metadata": {
        "id": "B-RC4OGVuq9-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.환경설정**"
      ],
      "metadata": {
        "id": "76Pw6f64d5VU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 경로 설정\n",
        "\n",
        "구글 드라이브 연결"
      ],
      "metadata": {
        "id": "1is0ZmzXeBrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kOfI9W-Kc8eF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e55825e5-aead-4f1b-ecce-051786b4e7e7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/project6_2/'"
      ],
      "metadata": {
        "id": "JhVujnYp4TJe"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/drive/MyDrive/project6_2/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FWlb0hwUiaT8",
        "outputId": "ad522510-eed5-4937-ba81-1cf4383ce96f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/project6_2/requirements.txt (line 1)) (1.54.4)\n",
            "Collecting datasets (from -r /content/drive/MyDrive/project6_2/requirements.txt (line 2))\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting haversine (from -r /content/drive/MyDrive/project6_2/requirements.txt (line 3))\n",
            "  Downloading haversine-2.8.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r /content/drive/MyDrive/project6_2/requirements.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r /content/drive/MyDrive/project6_2/requirements.txt (line 1)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r /content/drive/MyDrive/project6_2/requirements.txt (line 1)) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r /content/drive/MyDrive/project6_2/requirements.txt (line 1)) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai->-r /content/drive/MyDrive/project6_2/requirements.txt (line 1)) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai->-r /content/drive/MyDrive/project6_2/requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai->-r /content/drive/MyDrive/project6_2/requirements.txt (line 1)) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai->-r /content/drive/MyDrive/project6_2/requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2)) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2)) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2)) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2)) (2.32.3)\n",
            "Collecting xxhash (from datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2))\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2))\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2)) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2)) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai->-r /content/drive/MyDrive/project6_2/requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai->-r /content/drive/MyDrive/project6_2/requirements.txt (line 1)) (1.2.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2)) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2)) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2)) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2)) (4.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai->-r /content/drive/MyDrive/project6_2/requirements.txt (line 1)) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai->-r /content/drive/MyDrive/project6_2/requirements.txt (line 1)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r /content/drive/MyDrive/project6_2/requirements.txt (line 1)) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai->-r /content/drive/MyDrive/project6_2/requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai->-r /content/drive/MyDrive/project6_2/requirements.txt (line 1)) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2)) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2)) (2.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2)) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->-r /content/drive/MyDrive/project6_2/requirements.txt (line 2)) (1.16.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading haversine-2.8.1-py2.py3-none-any.whl (7.7 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, haversine, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 haversine-2.8.1 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.모듈 구성하기"
      ],
      "metadata": {
        "id": "9U7SbaB7cSSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/project6_2/emergency.py\n",
        "\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import *\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "\n",
        "from warnings import filterwarnings\n",
        "FutureWarning\n",
        "filterwarnings('ignore')\n",
        "\n",
        "path = '/content/drive/MyDrive/project6_2/' # 미리 지정\n",
        "er = pd.read_csv(path + '응급실 정보.csv') # 미리 지정\n",
        "#filename = 'audio2.mp3' # 사용자 input 예시\n",
        "#user_location = (37.35861845,127.1150359)  # 사용자 좌표 예시\n",
        "\n",
        "# 1. load_key(path)\n",
        "# 2. predict('audio_file')\n",
        "# 3. recommend_hospital()\n",
        "\n",
        "\n",
        "# 0-1. load file------------------\n",
        "def load_file(filepath):\n",
        "    with open(filepath, 'r') as file:\n",
        "        return file.readline().strip()\n",
        "\n",
        "# 0-2. load key file------------------\n",
        "def load_key(filepath):\n",
        "    api_key = load_file(filepath + 'api_key.txt')\n",
        "    openai.api_key = api_key\n",
        "\n",
        "    os.environ['OPENAI_API_KEY'] = api_key\n",
        "    return\n",
        "\n",
        "# 1-1 audio2text--------------------\n",
        "def audio_to_text(filename):\n",
        "    audio_path = path + 'audio/'\n",
        "    # OpenAI 클라이언트 생성\n",
        "    client = OpenAI()\n",
        "    audio_file = open(audio_path + filename, \"rb\")\n",
        "    # 오디오 파일을 읽어서, 위스퍼를 사용한 변환\n",
        "    transcript = client.audio.transcriptions.create(\n",
        "        file=audio_file,\n",
        "        model=\"whisper-1\",\n",
        "        language=\"ko\",\n",
        "        response_format=\"text\",\n",
        "    )\n",
        "    # 결과 반환\n",
        "    return transcript\n",
        "\n",
        "# 1-2 text2summary------------------\n",
        "def text_summary(input_text):\n",
        "    # OpenAI 클라이언트 생성\n",
        "    client = OpenAI()\n",
        "\n",
        "    # 시스템 역할과 응답 형식 지정\n",
        "    system_role = '''\n",
        "    당신은 응급 상황 텍스트에서 핵심 내용을 요약하고, 중증도를 정확히 예측해주는 어시스턴트입니다.\n",
        "    참고로 중증도 6등급은 응급상황과 전혀 관계없는 텍스트일 때 출력합니다.\n",
        "    응답은 다음의 형식을 지켜주세요:\n",
        "    {\n",
        "        \"summary\": \"텍스트 요약\",\n",
        "        \"severity\": \"예측한 중증도 ('1등급', '2등급', '3등급', '4등급', '5등급','6등급' 중 하나)\"\n",
        "    }\n",
        "    중증도는 응급 상황의 위험성과 시급성을 기준으로 예측하세요.\n",
        "    예시  요청{\n",
        "    'User_Input' : \"환자는 심한 흉통을 호소하며, 호흡곤란과 식은땀이 동반됩니다. 과거 병력으로는 심근경색이 있었으며, 현재 맥박이 매우 빠릅니다.\"\n",
        "    }\n",
        "    예시 출력\n",
        "    {\n",
        "        \"summary\": \"환자는 심한 흉통과 호흡곤란을 호소하며, 과거 심근경색 병력이 있습니다.\",\n",
        "        \"severity\": \"1등급\"\n",
        "    }\n",
        "    예시  요청{\n",
        "    'User_Input' : \"푸른 정원에 나비가 있어.\"\n",
        "    }\n",
        "    예시 출력\n",
        "    {\n",
        "        \"summary\": \"푸른 정원에 나비가 있어.\",\n",
        "        \"severity\": \"6등급\"\n",
        "    }\n",
        "    '''\n",
        "\n",
        "    # 입력데이터를 GPT-3.5-turbo에 전달하고 답변 받아오기\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_role\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": input_text\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # 응답 받기\n",
        "    answer = response.choices[0].message.content\n",
        "\n",
        "    # 응답형식을 정리하고 return\n",
        "    answer_dict = json.loads(answer)\n",
        "\n",
        "    return answer_dict['summary'], answer_dict['severity']\n",
        "\n",
        "\n",
        "# 2. model prediction------------------\n",
        "def predict(text, model, tokenizer):\n",
        "    # 입력 문장 토크나이징\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    inputs = {key: value.to(model.device) for key, value in inputs.items()}\n",
        "    # 모델 예측\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # 로짓을 소프트맥스로 변환하여 확률 계산\n",
        "    logits = outputs.logits\n",
        "    probabilities = logits.softmax(dim=1)\n",
        "\n",
        "    # 가장 높은 확률을 가진 클래스 선택\n",
        "    pred = torch.argmax(probabilities, dim=-1).item()\n",
        "\n",
        "    return pred, probabilities\n",
        "\n",
        "def predict_class(filename):\n",
        "    save_directory = path + \"km_bert/km_bert\"\n",
        "    model = BertForSequenceClassification.from_pretrained(save_directory)\n",
        "    tokenizer = BertTokenizer.from_pretrained(save_directory)\n",
        "\n",
        "    # summary\n",
        "    text,severity = text_summary(audio_to_text(filename))\n",
        "    if severity == '6등급':\n",
        "      return 6, text\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        max_length=128,\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\"  # PyTorch 텐서 반환\n",
        "    )\n",
        "\n",
        "    # Prediction\n",
        "    outputs = model(**inputs)\n",
        "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "    predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
        "\n",
        "    return predicted_class, text\n",
        "\n",
        "def info_treatment(input_text):\n",
        "    # OpenAI 클라이언트 생성\n",
        "    client = OpenAI()\n",
        "\n",
        "    # 시스템 역할과 응답 형식 지정\n",
        "    system_role = system_role = system_role =  '''\n",
        "    당신은 경미한 상태의 환자를 위해 정보를 요약하고 적절한 비응급 조치를 제안하는 도우미입니다.\n",
        "\n",
        "    역할:\n",
        "    1. 환자의 상태가 심각하지 않음을 전제로 제공된 정보를 요약합니다 (`info`).\n",
        "    2. 환자의 상태를 관리하기 위한 적절한 비응급 조치 순서를 제안합니다 (`treatment`).\n",
        "\n",
        "    응답 형식:\n",
        "    {\n",
        "        \"info\": \"상황 요약\",\n",
        "        \"treatment\": [\n",
        "            \"1. 첫 번째로 해야 할 비응급 조치\",\n",
        "            \"2. 두 번째로 해야 할 비응급 조치\",\n",
        "            \"3. 세 번째로 해야 할 비응급 조치 (필요 시 추가)\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    예시 입력:\n",
        "    {\n",
        "        'User_Input': \"환자가 가벼운 두통을 호소하며, 최근 충분한 수면을 취하지 못했다고 합니다. 특별한 병력은 없습니다.\"\n",
        "    }\n",
        "\n",
        "    예시 출력:\n",
        "    {\n",
        "        \"info\": \"환자는 가벼운 두통을 호소하며, 최근 수면 부족이 원인일 가능성이 있습니다.\",\n",
        "        \"treatment\": [\n",
        "            \"1. 환자가 충분히 휴식을 취할 수 있도록 안내합니다.\",\n",
        "            \"2. 물을 충분히 섭취하도록 권장합니다.\",\n",
        "            \"3. 증상이 지속되거나 악화되면 일반의를 방문하도록 합니다.\"\n",
        "        ]\n",
        "    }\n",
        "    '''\n",
        "    # 입력데이터를 GPT-3.5-turbo에 전달하고 답변 받아오기\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_role\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": input_text\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # 응답 받기\n",
        "    answer = response.choices[0].message.content\n",
        "\n",
        "    # 응답형식을 정리하고 return\n",
        "    answer_dict = json.loads(answer)\n",
        "    return answer_dict['info'], answer_dict['treatment']\n",
        "\n",
        "def make_emergency_data(emergecy_df):\n",
        "    emergency_locations = []\n",
        "\n",
        "    for _, row in emergecy_df.iterrows():\n",
        "        emergency_locations.append({\"name\": row[\"병원이름\"], \"coords\": (row[\"위도\"], row[\"경도\"])})\n",
        "    return emergency_locations\n",
        "\n",
        "def recommend_hospitals(user_location, emergency_locations, API_KEY_ID, API_KEY, max_distance=10, max_attempt_distance=50):\n",
        "    import requests\n",
        "    from math import radians, sin, cos, sqrt, atan2\n",
        "    # Haversine 함수\n",
        "    def haversine(coord1, coord2):\n",
        "        R = 6371.0  # 지구 반지름 (km)\n",
        "        lat1, lon1 = radians(coord1[0]), radians(coord1[1])\n",
        "        lat2, lon2 = radians(coord2[0]), radians(coord2[1])\n",
        "        dlat = lat2 - lat1\n",
        "        dlon = lon2 - lon1\n",
        "        a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
        "        c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
        "        return R * c\n",
        "\n",
        "    # Directions API 호출 함수\n",
        "    def get_travel_time_with_fallback(start_coords, end_coords):\n",
        "        url = \"https://naveropenapi.apigw.ntruss.com/map-direction/v1/driving\"\n",
        "        options = [\"trafast\", \"traoptimal\"]  # 사용할 옵션 순서\n",
        "        headers = {\n",
        "            \"X-NCP-APIGW-API-KEY-ID\": API_KEY_ID,\n",
        "            \"X-NCP-APIGW-API-KEY\": API_KEY\n",
        "        }\n",
        "\n",
        "        for option in options:\n",
        "            params = {\n",
        "                \"start\": f\"{start_coords[1]},{start_coords[0]}\",  # 경도, 위도 순서\n",
        "                \"goal\": f\"{end_coords[1]},{end_coords[0]}\",\n",
        "                \"option\": option\n",
        "            }\n",
        "\n",
        "            try:\n",
        "                response = requests.get(url, headers=headers, params=params)\n",
        "                response.raise_for_status()\n",
        "                data = response.json()\n",
        "\n",
        "                # 'route' 데이터 확인 및 처리\n",
        "                if \"route\" in data and option in data[\"route\"]:\n",
        "                    summary = data[\"route\"][option][0][\"summary\"]\n",
        "                    duration_ms = summary[\"duration\"]  # 소요 시간 (밀리초)\n",
        "                    distance_m = summary[\"distance\"]  # 도로 거리 (미터)\n",
        "                    return duration_ms / 1000, distance_m / 1000  # 초 단위, km 단위 반환\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                print(f\"{option} 옵션 실패: {e}\")\n",
        "            except KeyError as e:\n",
        "                print(f\"API 응답에서 예상치 못한 데이터 구조: {e}\")\n",
        "\n",
        "        # 모든 옵션 실패 시\n",
        "        return float(\"inf\"), float(\"inf\")\n",
        "\n",
        "    # 거리 기준 확장하며 병원 검색\n",
        "    current_distance = max_distance\n",
        "    while current_distance <= max_attempt_distance:\n",
        "        filtered_hospitals = [\n",
        "            loc for loc in emergency_locations\n",
        "            if haversine(user_location, loc[\"coords\"]) <= current_distance\n",
        "        ]\n",
        "\n",
        "        if filtered_hospitals:\n",
        "            results = []\n",
        "            for hospital in filtered_hospitals:\n",
        "                travel_time, road_distance = get_travel_time_with_fallback(user_location, hospital[\"coords\"])\n",
        "                if not (travel_time is None or travel_time == float(\"inf\")):  # 유효한 값만 추가\n",
        "                    results.append({\n",
        "                        \"name\": hospital[\"name\"],\n",
        "                        \"road_distance\": road_distance,\n",
        "                        \"travel_time\": travel_time\n",
        "                    })\n",
        "\n",
        "            if results:  # 유효한 결과가 있는 경우\n",
        "                top_3_hospitals = sorted(results, key=lambda x: x[\"travel_time\"])[:3]\n",
        "\n",
        "                print(\"추천 병원:\")\n",
        "                for hospital in top_3_hospitals:\n",
        "                    duration_in_seconds = hospital[\"travel_time\"]  # 초 단위 값\n",
        "                    hours = int(duration_in_seconds // 3600)\n",
        "                    minutes = int((duration_in_seconds % 3600) // 60)\n",
        "                    print(\n",
        "                        f\"- {hospital['name']}, 도로 거리: {hospital['road_distance']:.2f}km, \"\n",
        "                        f\"예상 소요 시간: {hours}시간 {minutes}분\"\n",
        "                    )\n",
        "                return  # 추천 병원 출력 후 종료\n",
        "        current_distance += 10\n",
        "\n",
        "    # 최대 거리까지 검색했지만 병원 없음\n",
        "    print(f\"{max_attempt_distance}km 내 유효한 병원을 찾을 수 없습니다.\")\n"
      ],
      "metadata": {
        "id": "HAyk26O8bFQJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97685436-43a6-4a1d-febe-2d594d4cc4d0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/project6_2/emergency.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "FfVxL-FMfy-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import *\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "\n",
        "from warnings import filterwarnings\n",
        "FutureWarning\n",
        "filterwarnings('ignore')\n",
        "\n",
        "path = '/content/drive/MyDrive/project6_2/' # 미리 지정\n",
        "er = pd.read_csv(path + '응급실 정보.csv') # 미리 지정\n",
        "#filename = 'audio2.mp3' # 사용자 input 예시\n",
        "#user_location = (37.35861845,127.1150359)  # 사용자 좌표 예시\n",
        "\n",
        "# 1. load_key(path)\n",
        "# 2. predict('audio_file')\n",
        "# 3. recommend_hospital()\n",
        "\n",
        "\n",
        "# 0-1. load file------------------\n",
        "def load_file(filepath):\n",
        "    with open(filepath, 'r') as file:\n",
        "        return file.readline().strip()\n",
        "\n",
        "# 0-2. load key file------------------\n",
        "def load_key(filepath):\n",
        "    api_key = load_file(filepath + 'api_key.txt')\n",
        "    openai.api_key = api_key\n",
        "\n",
        "    os.environ['OPENAI_API_KEY'] = api_key\n",
        "    return\n",
        "\n",
        "# 1-1 audio2text--------------------\n",
        "def audio_to_text(filename):\n",
        "    audio_path = path + 'audio/'\n",
        "    # OpenAI 클라이언트 생성\n",
        "    client = OpenAI()\n",
        "    audio_file = open(audio_path + filename, \"rb\")\n",
        "    # 오디오 파일을 읽어서, 위스퍼를 사용한 변환\n",
        "    transcript = client.audio.transcriptions.create(\n",
        "        file=audio_file,\n",
        "        model=\"whisper-1\",\n",
        "        language=\"ko\",\n",
        "        response_format=\"text\",\n",
        "    )\n",
        "    # 결과 반환\n",
        "    return transcript\n",
        "\n",
        "# 1-2 text2summary------------------\n",
        "def text_summary(input_text):\n",
        "    # OpenAI 클라이언트 생성\n",
        "    client = OpenAI()\n",
        "\n",
        "    # 시스템 역할과 응답 형식 지정\n",
        "    system_role = '''\n",
        "    당신은 응급 상황 텍스트에서 핵심 내용을 요약하고, 중증도를 정확히 예측해주는 어시스턴트입니다.\n",
        "    응답은 다음의 형식을 지켜주세요:\n",
        "    {\n",
        "        \"summary\": \"텍스트 요약\",\n",
        "        \"severity\": \"예측한 중증도 ('1등급', '2등급', '3등급', '4등급', '5등급' 중 하나)\"\n",
        "    }\n",
        "    중증도는 응급 상황의 위험성과 시급성을 기준으로 예측하세요.\n",
        "    예시  요청{\n",
        "    'User_Input' : \"환자는 심한 흉통을 호소하며, 호흡곤란과 식은땀이 동반됩니다. 과거 병력으로는 심근경색이 있었으며, 현재 맥박이 매우 빠릅니다.\"\n",
        "    }\n",
        "    예시 출력\n",
        "    {\n",
        "        \"summary\": \"환자는 심한 흉통과 호흡곤란을 호소하며, 과거 심근경색 병력이 있습니다.\",\n",
        "        \"severity\": \"1등급\"\n",
        "    }\n",
        "    '''\n",
        "\n",
        "    # 입력데이터를 GPT-3.5-turbo에 전달하고 답변 받아오기\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_role\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": input_text\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # 응답 받기\n",
        "    answer = response.choices[0].message.content\n",
        "\n",
        "    # 응답형식을 정리하고 return\n",
        "    answer_dict = json.loads(answer)\n",
        "\n",
        "    return answer_dict['summary'], answer_dict['severity']\n",
        "\n",
        "\n",
        "# 2. model prediction------------------\n",
        "def predict(text, model, tokenizer):\n",
        "    # 입력 문장 토크나이징\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    inputs = {key: value.to(model.device) for key, value in inputs.items()}\n",
        "    # 모델 예측\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # 로짓을 소프트맥스로 변환하여 확률 계산\n",
        "    logits = outputs.logits\n",
        "    probabilities = logits.softmax(dim=1)\n",
        "\n",
        "    # 가장 높은 확률을 가진 클래스 선택\n",
        "    pred = torch.argmax(probabilities, dim=-1).item()\n",
        "\n",
        "    return pred, probabilities\n",
        "\n",
        "def predict_class(filename):\n",
        "    save_directory = path + \"km_bert/km_bert\"\n",
        "    model = BertForSequenceClassification.from_pretrained(save_directory)\n",
        "    tokenizer = BertTokenizer.from_pretrained(save_directory)\n",
        "\n",
        "    # summary\n",
        "    text,_ = text_summary(audio_to_text(filename))\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        max_length=128,  # 모델이 처리할 수 있는 최대 길이 (일반적으로 512)\n",
        "        truncation=True,  # 최대 길이를 초과하는 부분을 잘라냄\n",
        "        padding=True,     # 배치 내에서 입력 길이를 동일하게 맞춤\n",
        "        return_tensors=\"pt\"  # PyTorch 텐서 반환\n",
        "    )\n",
        "\n",
        "    # Prediction\n",
        "    outputs = model(**inputs)\n",
        "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "    predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
        "\n",
        "    return predicted_class, text\n",
        "\n",
        "def info_treatment(input_text):\n",
        "    # OpenAI 클라이언트 생성\n",
        "    client = OpenAI()\n",
        "\n",
        "    # 시스템 역할과 응답 형식 지정\n",
        "    system_role = system_role = system_role =  '''\n",
        "    당신은 경미한 상태의 환자를 위해 정보를 요약하고 적절한 비응급 조치를 제안하는 도우미입니다.\n",
        "\n",
        "    역할:\n",
        "    1. 환자의 상태가 심각하지 않음을 전제로 제공된 정보를 요약합니다 (`info`).\n",
        "    2. 환자의 상태를 관리하기 위한 적절한 비응급 조치 순서를 제안합니다 (`treatment`).\n",
        "\n",
        "    응답 형식:\n",
        "    {\n",
        "        \"info\": \"상황 요약\",\n",
        "        \"treatment\": [\n",
        "            \"1. 첫 번째로 해야 할 비응급 조치\",\n",
        "            \"2. 두 번째로 해야 할 비응급 조치\",\n",
        "            \"3. 세 번째로 해야 할 비응급 조치 (필요 시 추가)\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    예시 입력:\n",
        "    {\n",
        "        'User_Input': \"환자가 가벼운 두통을 호소하며, 최근 충분한 수면을 취하지 못했다고 합니다. 특별한 병력은 없습니다.\"\n",
        "    }\n",
        "\n",
        "    예시 출력:\n",
        "    {\n",
        "        \"info\": \"환자는 가벼운 두통을 호소하며, 최근 수면 부족이 원인일 가능성이 있습니다.\",\n",
        "        \"treatment\": [\n",
        "            \"1. 환자가 충분히 휴식을 취할 수 있도록 안내합니다.\",\n",
        "            \"2. 물을 충분히 섭취하도록 권장합니다.\",\n",
        "            \"3. 증상이 지속되거나 악화되면 일반의를 방문하도록 합니다.\"\n",
        "        ]\n",
        "    }\n",
        "    '''\n",
        "    # 입력데이터를 GPT-3.5-turbo에 전달하고 답변 받아오기\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_role\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": input_text\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # 응답 받기\n",
        "    answer = response.choices[0].message.content\n",
        "\n",
        "    # 응답형식을 정리하고 return\n",
        "    answer_dict = json.loads(answer)\n",
        "    return answer_dict['info'], answer_dict['treatment']\n",
        "\n",
        "def make_emergency_data(emergecy_df):\n",
        "    emergency_locations = []\n",
        "\n",
        "    for _, row in emergecy_df.iterrows():\n",
        "        emergency_locations.append({\"name\": row[\"병원이름\"], \"coords\": (row[\"위도\"], row[\"경도\"])})\n",
        "    return emergency_locations\n",
        "\n",
        "def recommend_hospitals(user_location, emergency_locations, API_KEY_ID, API_KEY, max_distance=10, max_attempt_distance=50):\n",
        "    import requests\n",
        "    from math import radians, sin, cos, sqrt, atan2\n",
        "    # Haversine 함수\n",
        "    def haversine(coord1, coord2):\n",
        "        R = 6371.0  # 지구 반지름 (km)\n",
        "        lat1, lon1 = radians(coord1[0]), radians(coord1[1])\n",
        "        lat2, lon2 = radians(coord2[0]), radians(coord2[1])\n",
        "        dlat = lat2 - lat1\n",
        "        dlon = lon2 - lon1\n",
        "        a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
        "        c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
        "        return R * c\n",
        "\n",
        "    # Directions API 호출 함수\n",
        "    def get_travel_time_with_fallback(start_coords, end_coords):\n",
        "        url = \"https://naveropenapi.apigw.ntruss.com/map-direction/v1/driving\"\n",
        "        options = [\"trafast\", \"traoptimal\"]  # 사용할 옵션 순서\n",
        "        headers = {\n",
        "            \"X-NCP-APIGW-API-KEY-ID\": API_KEY_ID,\n",
        "            \"X-NCP-APIGW-API-KEY\": API_KEY\n",
        "        }\n",
        "\n",
        "        for option in options:\n",
        "            params = {\n",
        "                \"start\": f\"{start_coords[1]},{start_coords[0]}\",  # 경도, 위도 순서\n",
        "                \"goal\": f\"{end_coords[1]},{end_coords[0]}\",\n",
        "                \"option\": option\n",
        "            }\n",
        "\n",
        "            try:\n",
        "                response = requests.get(url, headers=headers, params=params)\n",
        "                response.raise_for_status()\n",
        "                data = response.json()\n",
        "\n",
        "                # 'route' 데이터 확인 및 처리\n",
        "                if \"route\" in data and option in data[\"route\"]:\n",
        "                    summary = data[\"route\"][option][0][\"summary\"]\n",
        "                    duration_ms = summary[\"duration\"]  # 소요 시간 (밀리초)\n",
        "                    distance_m = summary[\"distance\"]  # 도로 거리 (미터)\n",
        "                    return duration_ms / 1000, distance_m / 1000  # 초 단위, km 단위 반환\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                print(f\"{option} 옵션 실패: {e}\")\n",
        "            except KeyError as e:\n",
        "                print(f\"API 응답에서 예상치 못한 데이터 구조: {e}\")\n",
        "\n",
        "        # 모든 옵션 실패 시\n",
        "        return float(\"inf\"), float(\"inf\")\n",
        "\n",
        "    # 거리 기준 확장하며 병원 검색\n",
        "    current_distance = max_distance\n",
        "    while current_distance <= max_attempt_distance:\n",
        "        filtered_hospitals = [\n",
        "            loc for loc in emergency_locations\n",
        "            if haversine(user_location, loc[\"coords\"]) <= current_distance\n",
        "        ]\n",
        "\n",
        "        if filtered_hospitals:\n",
        "            results = []\n",
        "            for hospital in filtered_hospitals:\n",
        "                travel_time, road_distance = get_travel_time_with_fallback(user_location, hospital[\"coords\"])\n",
        "                if not (travel_time is None or travel_time == float(\"inf\")):  # 유효한 값만 추가\n",
        "                    results.append({\n",
        "                        \"name\": hospital[\"name\"],\n",
        "                        \"road_distance\": road_distance,\n",
        "                        \"travel_time\": travel_time\n",
        "                    })\n",
        "\n",
        "            if results:  # 유효한 결과가 있는 경우\n",
        "                top_3_hospitals = sorted(results, key=lambda x: x[\"travel_time\"])[:3]\n",
        "\n",
        "                print(\"추천 병원:\")\n",
        "                for hospital in top_3_hospitals:\n",
        "                    duration_in_seconds = hospital[\"travel_time\"]  # 초 단위 값\n",
        "                    hours = int(duration_in_seconds // 3600)\n",
        "                    minutes = int((duration_in_seconds % 3600) // 60)\n",
        "                    print(\n",
        "                        f\"- {hospital['name']}, 도로 거리: {hospital['road_distance']:.2f}km, \"\n",
        "                        f\"예상 소요 시간: {hours}시간 {minutes}분\"\n",
        "                    )\n",
        "                return  # 추천 병원 출력 후 종료\n",
        "        current_distance += 10\n",
        "\n",
        "    # 최대 거리까지 검색했지만 병원 없음\n",
        "    print(f\"{max_attempt_distance}km 내 유효한 병원을 찾을 수 없습니다.\")"
      ],
      "metadata": {
        "id": "D02PSu1TIYED"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_key(path)"
      ],
      "metadata": {
        "id": "-ZF4vBoUJZWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_to_text('audio2.mp3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PEwNCfFBKQla",
        "outputId": "8e276955-f3d5-4bcc-8136-2a9350c090a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'119죠. 제가 지금 열이 열이 올랐어요. 몇 도냐면은 38도 정도 돼요. 머리가 아프고 좀 띵한 것 같아요. 우한이 좀 들어요. 어떻게 해야 할까요?\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text,keywords = text_summary(audio_to_text('audio2.mp3'))\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2azW1mp_K41y",
        "outputId": "8b1f054c-7c0c-425f-feb1-a9ec48f3c4c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'응급 상황에서 초기 조치를 취해야 합니다. 체온이 38도로 높아지고 머리가 아프고 혼란스러운 증상이 있을 때는 즉시 의료진에 연락하거나 응급실을 방문해야 합니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_class('audio2.mp3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsrycAX8L41z",
        "outputId": "2709d440-1018-409d-f3ab-9da80541ea18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emergency_locations = make_emergency_data(er)"
      ],
      "metadata": {
        "id": "FgeWECFWbvuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_location = (37.35861845,127.1150359)\n",
        "recommend_hospitals(user_location, emergency_locations, API_KEY_ID, API_KEY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkpvUXABRioi",
        "outputId": "10090adc-5351-4d85-af75-04cbd2eb7281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "추천 병원:\n",
            "- 분당서울대학교병원, 도로 거리: 2.63km, 예상 소요 시간: 0시간 9분\n",
            "- 대진의료재단분당제생병원, 도로 거리: 4.71km, 예상 소요 시간: 0시간 14분\n",
            "- 국군수도병원, 도로 거리: 5.97km, 예상 소요 시간: 0시간 17분\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G1TenHwgRoHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zvoIbslvQrvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# text to audio"
      ],
      "metadata": {
        "id": "sCyLBGvoRmtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gtts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpjBWYJyQqne",
        "outputId": "3a1d912f-0da7-4e0d-cb0d-67d124c0d78c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gtts\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2024.8.30)\n",
            "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: gtts\n",
            "Successfully installed gtts-2.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "import os\n",
        "\n",
        "def text_to_audio(text, language='en', output_file='output.mp3'):\n",
        "    \"\"\"\n",
        "    Converts text to speech and saves it as an audio file.\n",
        "\n",
        "    Parameters:\n",
        "    - text (str): The text to convert to speech.\n",
        "    - language (str): Language for text-to-speech conversion (default is 'en' for English).\n",
        "    - output_file (str): The name of the output audio file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create gTTS object\n",
        "        tts = gTTS(text=text, lang=language, slow=False)\n",
        "\n",
        "        # Save the audio file\n",
        "        tts.save(output_file)\n",
        "        print(f\"Audio file saved as {output_file}\")\n",
        "\n",
        "        # Optionally, play the audio file\n",
        "        os.system(f\"start {output_file}\" if os.name == \"nt\" else f\"open {output_file}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"An error occurred:\", e)\n",
        "\n",
        "# Example Usage\n",
        "text = \"오래된 무릎 통증으로 환자가 계단을 오르내릴 때 약간의 불편감을 느낍니다.\"\n",
        "text_to_audio(text, language='ko', output_file='example2.mp3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kSF6hASQsmQ",
        "outputId": "7a581550-9bfe-4c9d-d6a5-c3724f424195"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio file saved as example2.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X9AcxOOpQ2Fa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}